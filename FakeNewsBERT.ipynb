{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "X028x9tvI9W0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import logging\n",
        "import itertools\n",
        "import random\n",
        "import warnings\n",
        "import time\n",
        "import os\n",
        "import datetime as dt\n",
        "import plotly.express as px\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.patches as mpatches\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout, SpatialDropout1D, Conv1D, GlobalMaxPooling1D, Flatten\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from sklearn import metrics\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import keras\n",
        "from keras_preprocessing.text import Tokenizer\n",
        "#from keras.preprocessing.sequence import pad_sequences\n",
        "# Setting some options for general use.\n",
        "\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "pd.options.display.max_columns = 250\n",
        "pd.options.display.max_rows = 250\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lrRAjXnnI9W5"
      },
      "outputs": [],
      "source": [
        "# dataset for model training\n",
        "model_data = pd.read_csv('news_articles.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "TYcuMoGBbJ8n",
        "outputId": "3455a5a3-1b1b-4c52-e55b-2253d28d3526"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>published</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>site_url</th>\n",
              "      <th>main_img_url</th>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "      <th>title_without_stopwords</th>\n",
              "      <th>text_without_stopwords</th>\n",
              "      <th>hasImage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Barracuda Brigade</td>\n",
              "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
              "      <td>muslims busted they stole millions in govt ben...</td>\n",
              "      <td>print they should pay all the back all the mon...</td>\n",
              "      <td>english</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>bias</td>\n",
              "      <td>Real</td>\n",
              "      <td>muslims busted stole millions govt benefits</td>\n",
              "      <td>print pay back money plus interest entire fami...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>reasoning with facts</td>\n",
              "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
              "      <td>re why did attorney general loretta lynch plea...</td>\n",
              "      <td>why did attorney general loretta lynch plead t...</td>\n",
              "      <td>english</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>bias</td>\n",
              "      <td>Real</td>\n",
              "      <td>attorney general loretta lynch plead fifth</td>\n",
              "      <td>attorney general loretta lynch plead fifth bar...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Barracuda Brigade</td>\n",
              "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
              "      <td>breaking weiner cooperating with fbi on hillar...</td>\n",
              "      <td>red state  \\nfox news sunday reported this mor...</td>\n",
              "      <td>english</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>bias</td>\n",
              "      <td>Real</td>\n",
              "      <td>breaking weiner cooperating fbi hillary email ...</td>\n",
              "      <td>red state fox news sunday reported morning ant...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fed Up</td>\n",
              "      <td>2016-11-01T05:22:00.000+02:00</td>\n",
              "      <td>pin drop speech by father of daughter kidnappe...</td>\n",
              "      <td>email kayla mueller was a prisoner and torture...</td>\n",
              "      <td>english</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
              "      <td>bias</td>\n",
              "      <td>Real</td>\n",
              "      <td>pin drop speech father daughter kidnapped kill...</td>\n",
              "      <td>email kayla mueller prisoner tortured isis cha...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fed Up</td>\n",
              "      <td>2016-11-01T21:56:00.000+02:00</td>\n",
              "      <td>fantastic trumps  point plan to reform healthc...</td>\n",
              "      <td>email healthcare reform to make america great ...</td>\n",
              "      <td>english</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
              "      <td>bias</td>\n",
              "      <td>Real</td>\n",
              "      <td>fantastic trumps point plan reform healthcare ...</td>\n",
              "      <td>email healthcare reform make america great sin...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 author                      published  \\\n",
              "0     Barracuda Brigade  2016-10-26T21:41:00.000+03:00   \n",
              "1  reasoning with facts  2016-10-29T08:47:11.259+03:00   \n",
              "2     Barracuda Brigade  2016-10-31T01:41:49.479+02:00   \n",
              "3                Fed Up  2016-11-01T05:22:00.000+02:00   \n",
              "4                Fed Up  2016-11-01T21:56:00.000+02:00   \n",
              "\n",
              "                                               title  \\\n",
              "0  muslims busted they stole millions in govt ben...   \n",
              "1  re why did attorney general loretta lynch plea...   \n",
              "2  breaking weiner cooperating with fbi on hillar...   \n",
              "3  pin drop speech by father of daughter kidnappe...   \n",
              "4  fantastic trumps  point plan to reform healthc...   \n",
              "\n",
              "                                                text language  \\\n",
              "0  print they should pay all the back all the mon...  english   \n",
              "1  why did attorney general loretta lynch plead t...  english   \n",
              "2  red state  \\nfox news sunday reported this mor...  english   \n",
              "3  email kayla mueller was a prisoner and torture...  english   \n",
              "4  email healthcare reform to make america great ...  english   \n",
              "\n",
              "              site_url                                       main_img_url  \\\n",
              "0  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
              "1  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
              "2  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
              "3  100percentfedup.com  http://100percentfedup.com/wp-content/uploads/...   \n",
              "4  100percentfedup.com  http://100percentfedup.com/wp-content/uploads/...   \n",
              "\n",
              "   type label                            title_without_stopwords  \\\n",
              "0  bias  Real        muslims busted stole millions govt benefits   \n",
              "1  bias  Real         attorney general loretta lynch plead fifth   \n",
              "2  bias  Real  breaking weiner cooperating fbi hillary email ...   \n",
              "3  bias  Real  pin drop speech father daughter kidnapped kill...   \n",
              "4  bias  Real  fantastic trumps point plan reform healthcare ...   \n",
              "\n",
              "                              text_without_stopwords  hasImage  \n",
              "0  print pay back money plus interest entire fami...       1.0  \n",
              "1  attorney general loretta lynch plead fifth bar...       1.0  \n",
              "2  red state fox news sunday reported morning ant...       1.0  \n",
              "3  email kayla mueller prisoner tortured isis cha...       1.0  \n",
              "4  email healthcare reform make america great sin...       1.0  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "G6gYjBkbCVPh",
        "outputId": "cfe632a1-657b-48bb-9783-5715dd476491"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_without_stopwords</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>print pay back money plus interest entire fami...</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>attorney general loretta lynch plead fifth bar...</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>red state fox news sunday reported morning ant...</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>email kayla mueller prisoner tortured isis cha...</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>email healthcare reform make america great sin...</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2091</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2092</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2093</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2094</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2095</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2096 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 text_without_stopwords label\n",
              "0     print pay back money plus interest entire fami...  Real\n",
              "1     attorney general loretta lynch plead fifth bar...  Real\n",
              "2     red state fox news sunday reported morning ant...  Real\n",
              "3     email kayla mueller prisoner tortured isis cha...  Real\n",
              "4     email healthcare reform make america great sin...  Real\n",
              "...                                                 ...   ...\n",
              "2091                                                NaN  Real\n",
              "2092                                                NaN  Real\n",
              "2093                                                NaN  Fake\n",
              "2094                                                NaN  Fake\n",
              "2095                                                NaN   NaN\n",
              "\n",
              "[2096 rows x 2 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## picking the relevant columns\n",
        "model_data = model_data[['text_without_stopwords', 'label']]\n",
        "model_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6t2k5h8LCc-J"
      },
      "outputs": [],
      "source": [
        "## specifying the clean text as  string\n",
        "model_data.text_without_stopwords=model_data.text_without_stopwords.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dWhsHYIpI9W_"
      },
      "outputs": [],
      "source": [
        "## to silence warning\n",
        "os.environ[\"WANDB_API_KEY\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LZHpESIeI9XA",
        "outputId": "f4e13ac6-409c-4df1-f852-cc5e37dc7e57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of replicas: 1\n"
          ]
        }
      ],
      "source": [
        "## using the TPU in trainig\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except ValueError:\n",
        "    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n",
        "    print('Number of replicas:', strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0vUveONAJGFQ"
      },
      "outputs": [],
      "source": [
        "## dealing with randomness in results\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import random\n",
        "random.set_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezgip4IsI9W_"
      },
      "source": [
        "________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NgHdLIA6I9XC"
      },
      "outputs": [],
      "source": [
        "## splitting to get the development data\n",
        "train, test = train_test_split(model_data, test_size = 0.20, random_state = 1)\n",
        "x_train, dev = train_test_split(train, test_size=0.20, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjNJrCiqQuAy",
        "outputId": "11df6c44-fc22-4271-dd1a-2176335eecc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1340, 2)\n",
            "(420, 2)\n",
            "(336, 2)\n"
          ]
        }
      ],
      "source": [
        "## printing the data shapes\n",
        "print(x_train.shape)\n",
        "print(test.shape)\n",
        "print(dev.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUPytFnmI9XD",
        "outputId": "ed6fe0b6-ecca-45dd-c0df-cc9a64c94b0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Real', 'Fake', nan]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## the label consist of neutral, negative and positive\n",
        "labels = model_data.label.unique().tolist()\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efx5LNdNI9XD",
        "outputId": "65e7b452-5bc4-4abb-9bee-f2891a499a6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_train (1676, 1)\n",
            "y_test (420, 1)\n",
            "y_dev (336, 1)\n"
          ]
        }
      ],
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(model_data.label.tolist())\n",
        "\n",
        "y_train = encoder.transform(train.label.tolist())\n",
        "y_test = encoder.transform(test.label.tolist())\n",
        "y_dev = encoder.transform(dev.label.tolist())\n",
        "\n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_test = y_test.reshape(-1,1)\n",
        "y_dev = y_dev.reshape(-1,1)\n",
        "\n",
        "print(\"y_train\",y_train.shape)\n",
        "print(\"y_test\",y_test.shape)\n",
        "print(\"y_dev\",y_dev.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wbpMHGFzI9XA"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "max_length = 128\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "u17MC5RrI9XB"
      },
      "outputs": [],
      "source": [
        "# Bert Tokenizer\n",
        "seed(1)\n",
        "random.set_seed(1)\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FR07KAPOI9XE"
      },
      "outputs": [],
      "source": [
        "def bert_encode(data):\n",
        "    seed(1)\n",
        "    random.set_seed(1)\n",
        "    tokens = tokenizer.batch_encode_plus(data, max_length=max_length, padding='max_length', truncation=True)\n",
        "\n",
        "    return tf.constant(tokens['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QAc76MQ0I9XE"
      },
      "outputs": [],
      "source": [
        "train_encoded = bert_encode(train.text_without_stopwords)\n",
        "dev_encoded = bert_encode(dev.text_without_stopwords)\n",
        "seed(1)\n",
        "random.set_seed(1)\n",
        "\n",
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((train_encoded, y_train))\n",
        "    .shuffle(128)\n",
        "    .batch(batch_size)\n",
        ")\n",
        "\n",
        "dev_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((dev_encoded, y_dev))\n",
        "    .shuffle(128)\n",
        "    .batch(batch_size)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "7623ace91d4d4f12a3c2854509f9ea88",
            "28db3dc5ec1c4f0e8211dc6574f69693",
            "ec81c2e448d54e47bf594669b7881a07",
            "63a4e0bf78774894a6cfec73154bb954",
            "7259bd3799004268a3966cbeea7a304d",
            "5407f9b2de024f6cb22936d324c5acb0",
            "b8068da246af452a8e624eec07944d94",
            "b57865cce7c54117a551096299501bec",
            "f37d8dfc245d4479b80795efe6c229f9",
            "3774a146dedf44d09be0fad8cbd1d606",
            "29acdad25e4b40e8916169cd8b7307db"
          ]
        },
        "id": "exi77v8GEAIW",
        "outputId": "0cf91901-99f2-4e10-f8b7-c258bc82d04f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "#BERT-BILSTM-FC Model Building\n",
        "seed(1)\n",
        "random.set_seed(1)\n",
        "with strategy.scope():\n",
        "  bert_encoder = TFBertModel.from_pretrained(model_name)\n",
        "  input_word_ids = tf.keras.Input(shape=(max_length,), dtype=tf.int32, name=\"input_ids\")\n",
        "  last_hidden_states = bert_encoder(input_word_ids)[0]\n",
        "  x = tf.keras.layers.SpatialDropout1D(0.2)(last_hidden_states)\n",
        "\n",
        "  x = tf.keras.layers.Dense(10, activation = 'relu')(x) #2\n",
        "\n",
        "  x = tf.keras.layers.Dense(10, activation = 'relu')(x) #2\n",
        "\n",
        "  x = tf.keras.layers.Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2))(x)\n",
        "\n",
        "  x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "  x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "  x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "\n",
        "  x = tf.keras.layers.Dropout(0.3)(x)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "  model = tf.keras.Model(input_word_ids, outputs)\n",
        "\n",
        "  adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=adam_optimizer,metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW8mXVClE_10",
        "outputId": "62a746fe-6fff-4023-d892-660357023476"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_ids (InputLayer)      [(None, 128)]             0         \n",
            "                                                                 \n",
            " tf_bert_model (TFBertModel  TFBaseModelOutputWithPo   109482240 \n",
            " )                           olingAndCrossAttentions             \n",
            "                             (last_hidden_state=(Non             \n",
            "                             e, 128, 768),                       \n",
            "                              pooler_output=(None, 7             \n",
            "                             68),                                \n",
            "                              past_key_values=None,              \n",
            "                             hidden_states=None, att             \n",
            "                             entions=None, cross_att             \n",
            "                             entions=None)                       \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 128, 768)          0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128, 10)           7690      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128, 10)           110       \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 128)               38400     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109553403 (417.91 MB)\n",
            "Trainable params: 109553403 (417.91 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "## model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7DUeZsuhI9XG",
        "outputId": "124ae866-a840-4af8-bc7e-98a352ede3c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
          ]
        }
      ],
      "source": [
        "## model plotting\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foDYQweuI9XG",
        "outputId": "7dd09381-c57f-42ab-c792-d5a795dda72a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            " 2/14 [===>..........................] - ETA: 2:55:51 - loss: 1.1238 - accuracy: 0.3164"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\User\\Desktop\\TDA\\Assignments\\Supervised ML Project\\FakeNewsBERT.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/TDA/Assignments/Supervised%20ML%20Project/FakeNewsBERT.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m seed(\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/TDA/Assignments/Supervised%20ML%20Project/FakeNewsBERT.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m random\u001b[39m.\u001b[39mset_seed(\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/TDA/Assignments/Supervised%20ML%20Project/FakeNewsBERT.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/TDA/Assignments/Supervised%20ML%20Project/FakeNewsBERT.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     train_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/TDA/Assignments/Supervised%20ML%20Project/FakeNewsBERT.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/TDA/Assignments/Supervised%20ML%20Project/FakeNewsBERT.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/TDA/Assignments/Supervised%20ML%20Project/FakeNewsBERT.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mdev_dataset, verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Model Training\n",
        "seed(1)\n",
        "random.set_seed(1)\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=dev_dataset, verbose = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUOVFNfSepMn"
      },
      "outputs": [],
      "source": [
        "## weight saving\n",
        "model.save_weights('fakenewslabel.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC9hYMmLI9XR",
        "outputId": "017c7242-5d5b-42d7-d2cb-8b07eae5d544"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "test_encoded = bert_encode(test.text_without_stopwords)\n",
        "\n",
        "test_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices(test_encoded)\n",
        "    .batch(batch_size)\n",
        ")\n",
        "\n",
        "predicted_chats = model.predict(test_dataset, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m6NE4dLI9XS"
      },
      "outputs": [],
      "source": [
        "y_pred = []\n",
        "for i in range(predicted_chats.shape[0]):\n",
        "    y_pred.append(np.argmax(predicted_chats[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJgU4xriI9XS",
        "outputId": "e99ed8ac-eef5-4f56-c388-4bf5563566d0"
      },
      "outputs": [],
      "source": [
        "## classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_chy3ayN0mY",
        "outputId": "e4a04e43-7d98-49f7-96ed-7debf069b7ce"
      },
      "outputs": [],
      "source": [
        "## errors\n",
        "meanAbErr = metrics.mean_absolute_error(y_test, y_pred)\n",
        "meanSqErr = metrics.mean_squared_error(y_test, y_pred)\n",
        "rootMeanSqErr = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
        "print('Mean Absolute Error:', meanAbErr)\n",
        "print('Mean Square Error:', meanSqErr)\n",
        "print('Root Mean Square Error:', rootMeanSqErr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMzaVGOz_2aq",
        "outputId": "3bff57d2-c8d6-4938-a016-66c0286248ce"
      },
      "outputs": [],
      "source": [
        "## confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "sgldYoZW1uOL",
        "outputId": "93837b32-926d-4fcf-d6ab-46b6d573125d"
      },
      "outputs": [],
      "source": [
        "##plotting the confusion matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(6, 6), cmap=plt.cm.Greens)\n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Confusion Matrix', fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpBkw111e8JZ"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_CBDyTVyKwG"
      },
      "outputs": [],
      "source": [
        "def decode_sentiment(score):\n",
        "    if score == 0:\n",
        "        return \"Fake\"\n",
        "    else:\n",
        "        return \"Real\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCaQ_y65zC8P"
      },
      "outputs": [],
      "source": [
        "text = input(\"Please input your text or review: \")\n",
        "def predict(text):\n",
        "    start_at = time.time()\n",
        "    # Tokenize text\n",
        "    x_encoded = bert_encode([text])\n",
        "    # Predict\n",
        "    score = model.predict([x_encoded])[0]\n",
        "    # Decode sentiment\n",
        "    label = decode_sentiment(np.argmax(score))\n",
        "\n",
        "    return {\"label\": label, \"score\": score,\n",
        "            \"elapsed_time\": time.time() - start_at}\n",
        "predict(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEUfAqtZYp19"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('allin')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "2b51d935537cf170dad0bd4ef02a82a41c20939f72c6c68869d48b39a03a99f8"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "28db3dc5ec1c4f0e8211dc6574f69693": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5407f9b2de024f6cb22936d324c5acb0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b8068da246af452a8e624eec07944d94",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "29acdad25e4b40e8916169cd8b7307db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3774a146dedf44d09be0fad8cbd1d606": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5407f9b2de024f6cb22936d324c5acb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a4e0bf78774894a6cfec73154bb954": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3774a146dedf44d09be0fad8cbd1d606",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_29acdad25e4b40e8916169cd8b7307db",
            "value": " 440M/440M [00:07&lt;00:00, 44.7MB/s]"
          }
        },
        "7259bd3799004268a3966cbeea7a304d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7623ace91d4d4f12a3c2854509f9ea88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28db3dc5ec1c4f0e8211dc6574f69693",
              "IPY_MODEL_ec81c2e448d54e47bf594669b7881a07",
              "IPY_MODEL_63a4e0bf78774894a6cfec73154bb954"
            ],
            "layout": "IPY_MODEL_7259bd3799004268a3966cbeea7a304d"
          }
        },
        "b57865cce7c54117a551096299501bec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8068da246af452a8e624eec07944d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec81c2e448d54e47bf594669b7881a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b57865cce7c54117a551096299501bec",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f37d8dfc245d4479b80795efe6c229f9",
            "value": 440449768
          }
        },
        "f37d8dfc245d4479b80795efe6c229f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
